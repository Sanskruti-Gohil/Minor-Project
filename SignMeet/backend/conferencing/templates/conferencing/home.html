{% extends 'conferencing/base.html' %}
{% load static %}

{% block content %}
<h2 id="title">Join a Video Call</h2>
<link rel="stylesheet" type="text/css" href="{% static 'conferencing/css/home.css' %}">
<div id="joinSection">
    <form id="roomForm" method="GET">
        <div>
            <label for="userName">Enter Name:</label>
            <input type="text" id="userName" name="userName" placeholder="Your Name" required>
        </div>
        <div>
            <label for="roomName">Enter Room Name:</label>
            <input type="text" id="roomName" name="roomName" placeholder="Room Name" required>
        </div>
        <button type="submit">Join</button>
    </form>
</div>
<div id="roomSection" style="display: none;">
    <div id="video_container"></div>
    <div id="controls">
        <button id="leaveBtn">Leave</button>
        <button id="camBtn" disabled>Turn On Camera</button>
        <button id="micBtn" disabled>Turn On Mic</button>
        <button id="detectBtn" disabled>Detect Sign Language</button>
    </div>
    <div id="subtitle">Translation: [None]</div>
</div>

<script src="https://cdn.agora.io/sdk/release/AgoraRTC_N-4.19.0.js?nocache=202503162"></script>
<script src="https://docs.opencv.org/4.x/opencv.js" async></script>
<script>
    let client = null;
    let localTracks = { videoTrack: null, audioTrack: null };
    let localVideoElement = null;
    let remoteUsers = {};
    let ws = null;
    let isDetecting = false;
    let uid = null;

    const title = document.getElementById('title');
    const joinSection = document.getElementById('joinSection');
    const roomSection = document.getElementById('roomSection');
    const videoContainer = document.getElementById('video_container');
    const subtitle = document.getElementById('subtitle');
    const leaveBtn = document.getElementById('leaveBtn');
    const camBtn = document.getElementById('camBtn');
    const micBtn = document.getElementById('micBtn');
    const detectBtn = document.getElementById('detectBtn');

    console.log("title:", !!title);
    console.log("joinSection:", !!joinSection);
    console.log("roomSection:", !!roomSection);
    console.log("videoContainer:", !!videoContainer);
    console.log("subtitle:", !!subtitle);
    console.log("leaveBtn:", !!leaveBtn);
    console.log("camBtn:", !!camBtn);
    console.log("micBtn:", !!micBtn);
    console.log("detectBtn:", !!detectBtn);

    async function fetchToken(roomName) {
        const response = await fetch(`/get_token/?channelName=${encodeURIComponent(roomName)}`);
        const data = await response.json();
        if (data.error) throw new Error(data.error);
        return data;
    }

    const form = document.getElementById('roomForm');
    form.onsubmit = async function(event) {
        event.preventDefault();
        const userName = document.getElementById('userName').value.trim();
        const roomName = document.getElementById('roomName').value.trim();
        if (userName && roomName) {
            const APP_ID = "71fbf1e2263a49869725faa8404523ec";
            try {
                const { token, uid: newUid } = await fetchToken(roomName);
                uid = newUid;

                client = AgoraRTC.createClient({ mode: "rtc", codec: "vp8" });
                console.log("Client created with ID:", client._clientId);

                client.on('user-published', handleUserPublished);
                client.on('user-unpublished', handleUserUnpublished);

                await client.join(APP_ID, roomName, token, uid);
                console.log("Channel joined with UID:", uid);

                localTracks.videoTrack = await AgoraRTC.createCameraVideoTrack({
                    encoderConfig: { width: 229, height: 229, frameRate: 15, bitrateMin: 300, bitrateMax: 500 }
                });
                console.log("Video track created:", localTracks.videoTrack);
                const videoStreamTrack = localTracks.videoTrack.getMediaStreamTrack();
                if (videoStreamTrack.readyState !== "live") {
                    console.warn("Video track is not live. ReadyState:", videoStreamTrack.readyState);
                    alert("Video track is not live.");
                    localTracks.videoTrack = null;
                }

                if (localTracks.videoTrack) {
                    localVideoElement = document.createElement("video");
                    localVideoElement.id = `user-video-${uid}`;
                    localVideoElement.style.width = "229px";
                    localVideoElement.style.height = "229px";
                    localVideoElement.muted = true;
                    localVideoElement.autoplay = true;
                    videoContainer.appendChild(localVideoElement);
                    const stream = new MediaStream();
                    stream.addTrack(localTracks.videoTrack.getMediaStreamTrack());
                    localVideoElement.srcObject = stream;
                    await localVideoElement.play().catch(err => {
                        console.error("Video play failed:", err);
                        alert("Failed to play video: " + err.message);
                    });
                    console.log("Video element playing, currentTime:", localVideoElement.currentTime);
                    localTracks.videoTrack._videoElement = localVideoElement;
                    await client.publish(localTracks.videoTrack);
                    console.log("Video track published");
                }

                title.style.display = 'none'; // Hide the title
                joinSection.style.display = 'none';
                roomSection.style.display = 'block';
                camBtn.disabled = false;
                micBtn.disabled = false;
                detectBtn.disabled = !localTracks.videoTrack;
            } catch (err) {
                console.error("Failed to join room:", err);
                alert("Failed to join room: " + err.message + ". Check token generation or permissions.");
                if (client) {
                    await client.leave();
                }
            }
        } else {
            alert('Please enter both name and room name!');
        }
    };

    leaveBtn.onclick = async () => {
        console.log("Leave button clicked");
        for (let trackName in localTracks) {
            if (localTracks[trackName]) {
                localTracks[trackName].stop();
                localTracks[trackName].close();
                console.log(`${trackName} stopped and closed`);
            }
        }
        localTracks = { videoTrack: null, audioTrack: null };
        localVideoElement = null;
        if (ws) ws.close();
        if (client) await client.leave();
        videoContainer.innerHTML = '';
        title.style.display = 'block'; // Show the title again
        joinSection.style.display = 'block';
        roomSection.style.display = 'none';
        leaveBtn.disabled = true;
        camBtn.disabled = true;
        micBtn.disabled = true;
        detectBtn.disabled = true;
        camBtn.textContent = "Turn On Camera";
        micBtn.textContent = "Turn On Mic";
        subtitle.textContent = "Translation: [None]";
        console.log("Left channel");
    };

    camBtn.onclick = async () => {
        console.log("Camera button clicked");
        if (!localTracks.videoTrack) {
            try {
                localTracks.videoTrack = await AgoraRTC.createCameraVideoTrack({
                    encoderConfig: { width: 229, height: 229, frameRate: 15, bitrateMin: 300, bitrateMax: 500 }
                });
                console.log("Video track created:", localTracks.videoTrack);
                const videoStreamTrack = localTracks.videoTrack.getMediaTrackStream();
                if (videoStreamTrack.readyState !== "live") {
                    console.warn("Video track is not live. ReadyState:", videoStreamTrack.readyState);
                    alert("Video track is not live.");
                    localTracks.videoTrack = null;
                    return;
                }
                localVideoElement = document.createElement("video");
                localVideoElement.id = `user-video-${uid}`;
                localVideoElement.style.width = "229px";
                localVideoElement.style.height = "229px";
                localVideoElement.muted = true;
                localVideoElement.autoplay = true;
                videoContainer.appendChild(localVideoElement);
                const stream = new MediaStream();
                stream.addTrack(localTracks.videoTrack.getMediaStreamTrack());
                localVideoElement.srcObject = stream;
                await localVideoElement.play().catch(err => {
                    console.error("Video play failed:", err);
                    alert("Failed to play video: " + err.message);
                });
                console.log("Video element playing, currentTime:", localVideoElement.currentTime);
                localTracks.videoTrack._videoElement = localVideoElement;
                await client.publish(localTracks.videoTrack);
                console.log("Video track published");
                camBtn.textContent = "Turn Off Camera";
                detectBtn.disabled = false;
            } catch (err) {
                console.error("Failed to create or publish video track:", err);
                alert("Camera access or publish failed: " + err.message);
                return;
            }
        } else {
            localTracks.videoTrack.setEnabled(!localTracks.videoTrack.enabled);
            camBtn.textContent = localTracks.videoTrack.enabled ? "Turn Off Camera" : "Turn On Camera";
            console.log("Camera toggled, enabled:", localTracks.videoTrack.enabled);
            detectBtn.disabled = !localTracks.videoTrack.enabled;
        }
    };

    micBtn.onclick = async () => {
        console.log("Mic button clicked");
        if (!localTracks.audioTrack) {
            try {
                localTracks.audioTrack = await AgoraRTC.createMicrophoneAudioTrack();
                console.log("Audio track created:", localTracks.audioTrack);
                const audioStreamTrack = localTracks.audioTrack.getMediaStreamTrack();
                if (audioStreamTrack.readyState !== "live") {
                    console.warn("Audio track is not live. ReadyState:", audioStreamTrack.readyState);
                    alert("Audio track is not live.");
                    localTracks.audioTrack = null;
                    return;
                }
                await client.publish(localTracks.audioTrack);
                console.log("Audio track published");
                micBtn.textContent = "Turn Off Mic";
            } catch (err) {
                console.error("Failed to create or publish audio track:", err);
                alert("Microphone access or publish failed: " + err.message);
                return;
            }
        } else {
            localTracks.audioTrack.setEnabled(!localTracks.audioTrack.enabled);
            micBtn.textContent = localTracks.audioTrack.enabled ? "Turn Off Mic" : "Turn On Mic";
            console.log("Mic toggled, enabled:", localTracks.audioTrack.enabled);
        }
    };

    detectBtn.onclick = () => {
        console.log("Detect button clicked");
        if (!localTracks.videoTrack || !localTracks.videoTrack._videoElement) {
            alert("No video track or feed available.");
            return;
        }
        if (!ws || ws.readyState !== WebSocket.OPEN) {
            alert("WebSocket connection not established. Try rejoining the call.");
            return;
        }

        if (isDetecting) {
            isDetecting = false;
            detectBtn.textContent = "Detect Sign Language";
            subtitle.textContent = "Translation: [None]";
            console.log("Stopped sign language detection");
            return;
        }

        isDetecting = true;
        detectBtn.textContent = "Stop Detection";
        detectSigns();
    };

    function detectSigns() {
        const videoElement = localTracks.videoTrack._videoElement;

        function captureAndSendFrame() {
            if (!isDetecting) return;

            if (videoElement.readyState < 2 || !cv) {
                console.warn("Video not ready or OpenCV not loaded, readyState:", videoElement.readyState);
                setTimeout(captureAndSendFrame, 500);
                return;
            }

            const canvas = document.createElement('canvas');
            canvas.width = 229;
            canvas.height = 229;
            const context = canvas.getContext('2d');
            context.drawImage(videoElement, 0, 0, 229, 229);

            let imageData = context.getImageData(0, 0, 229, 229);
            let data = imageData.data;

            let rgbData = new Uint8Array(229 * 229 * 3);
            for (let i = 0, j = 0; i < data.length && j < rgbData.length; i += 4, j += 3) {
                rgbData[j] = data[i];
                rgbData[j + 1] = data[i + 1];
                rgbData[j + 2] = data[i + 2];
            }

            console.log(`Sending frame, byte length: ${rgbData.length}`);
            ws.send(rgbData);
            setTimeout(captureAndSendFrame, 500);
        }

        function onOpenCvReady() {
            cv = window.cv;
            console.log("OpenCV loaded");
            captureAndSendFrame();
        }
        if (typeof cv === 'undefined') {
            window.addEventListener('opencv.js', onOpenCvReady);
        } else {
            onOpenCvReady();
        }
    }

    async function handleUserPublished(user, mediaType) {
        console.log("User published:", user.uid, mediaType);
        await client.subscribe(user, mediaType);
        if (mediaType === 'video') {
            const player = document.createElement("div");
            player.id = `remote-user-${user.uid}`;
            player.style.width = "400px";
            player.style.height = "300px";
            videoContainer.appendChild(player);
            user.videoTrack.play(player);
        }
        if (mediaType === 'audio') user.audioTrack.play();
    }

    function handleUserUnpublished(user) {
        console.log("User unpublished:", user.uid);
        const player = document.getElementById(`remote-user-${user.uid}`);
        if (player) player.remove();
    }

    // WebSocket setup
    ws = new WebSocket('ws://' + window.location.host + '/ws/sign_detection/');
    ws.onopen = () => console.log("WebSocket connected for sign detection");
    ws.onmessage = (event) => {
        const translation = event.data;
        subtitle.textContent = `Translation: ${translation}`;
        console.log("Received translation:", translation);
    };
    ws.onclose = () => console.log("WebSocket connection closed");
    ws.onerror = (error) => console.error("WebSocket error:", error);
</script>
{% endblock %}